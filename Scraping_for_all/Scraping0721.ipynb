{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL********************************************************\n",
      "http://anonhq.com/london-terror-attacks-brits-celebrating-beer-hero/\n",
      "TITLE********************************************************\n",
      "London Terror Attacks: Brits are celebrating ‘beer-hero’\n",
      "DATE********************************************************\n",
      "2017-06-04T06:43:46+00:00\n",
      "AUTHOR********************************************************\n",
      "hqanon\n",
      "ARTICLE********************************************************\n",
      "['Photo: Twitter / Howard Mannella', 'Rush? Panic? Not for the guy on the right. He has totally different priorities…\\xa0', '', 'On saturday evening, a white van hit pedestrians on London Bridge at about 22:00 p.m. (BST) before three men got out and start stabbing people in nearby Borough Market with large knives. Nearly all people are running away in panic and shock in the direction showed them by police.', 'Only one guy seems to take it easy.', \"People fleeing #LondonBridge but the bloke on the right isn't spilling a drop. God Bless the Brits! pic.twitter.com/ceeaH0XxeX\", '— Howard Mannella (@hmannella) June 3, 2017', '', 'And Twitter loves him for that!', 'As everbody around him is running, he is walking calmly so he wouldn’t spill any drop of his precious drink.', \"do you blame him lol. He's got some skills.\", '— Amy (@Amynamo) June 3, 2017', '', 'https://twitter.com/mrwhitepaisley/status/871152049781698560?ref_src=twsrc%5Etfw&ref_url=http%3A%2F%2Fwww.bild.de%2Fnews%2Fausland%2Flondon%2Fterror-dieser-mann-bleibt-ruhig-52039080.bild.html', 'Hey, he paid for his pint.', '— Angelica Gino (@LaSylphide14) June 4, 2017', '', 'Not all heroes wear capes', '— The dude (@JannesKoecher) June 3, 2017', '', '\"Whats that mate? Attack? Nah mate, just ordered a pint!', '— Kiefer (@JustMeZedek) June 3, 2017', '', 'And let one of those knife wielding Assholes just try and take it from him, too.', 'I DARE them', '— Boshua Q. Bear, Ret. (@jcotera1106) June 3, 2017', '', 'This guy will surely turn into an internet meme.', 'Anonymous recommends: Click Here To Surf & Download Anonymously, Protect Yourself From Any Hackers Or Spy Agencies And Get Around Censorship Filters', \"Do you like our independent & investigative news? Then please check these two settings on Facebook to guarantee you don't miss our posts: \"]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import dateutil.parser as parser\n",
    "import time\n",
    "from urllib.parse import urlparse\n",
    "class News:\n",
    "    Article = ''\n",
    "    Title = ''\n",
    "    Author = ''\n",
    "    OriginalContent = ''\n",
    "    CreatedDate = ''\n",
    "    FetchedDate = ''\n",
    "    ArticleUrl = ''\n",
    "    LastUsed = ''\n",
    "    \n",
    "    def __init__(self, article , title , author , originalcontent , createddate , fetcheddate , articleurl , lastused ):\n",
    "        self.Article = article\n",
    "        self.Title = title\n",
    "        self.OriginalContent = originalcontent\n",
    "        self.CreatedDate = createddate\n",
    "        self.FetchedDate = fetcheddate\n",
    "        self.ArticleUrl = articleurl\n",
    "        self.LastUsed = lastused\n",
    "        self.Author = author\n",
    "        \n",
    "def scraping(href):\n",
    "    headers = {'user-agent' : 'Mozilla/5.0'}\n",
    "    if (requests.get(href, headers = headers)):\n",
    "        source = requests.get(href, headers = headers)\n",
    "        if (BeautifulSoup(source.content, \"lxml\")):\n",
    "            soup = BeautifulSoup(source.content, \"lxml\").body \n",
    "            news = News(None, None, None, None, None, None, None, None)\n",
    "            \n",
    "            date = time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time()))\n",
    "            news.fetchedDate = date\n",
    "            news.lastUsed = date \n",
    "            news.articleUrl = href\n",
    "            \n",
    "            class_list_main = [    \n",
    "                        'col-md-12',\n",
    "                        'content-wrapper clearfix detail-block-md',\n",
    "                        'content content--article section-us-news tonal tonal--tone-news',\n",
    "                        'entry-content',\n",
    "                        'column column-two-third site-content',\n",
    "                        'large-8 medium-12 columns first',\n",
    "                        'article',\n",
    "                        'article_body',\n",
    "                        'Article_inner-container_SZATq',\n",
    "                        'b-item',\n",
    "                        'container',\n",
    "                        'span8',\n",
    "                        'primary',\n",
    "                        'l-container',\n",
    "                        'row',\n",
    "                        'story theme-main   '\n",
    "            ]\n",
    "            \n",
    "            for i in range(len(class_list_main)):\n",
    "                if (soup.findAll(\"\",{'class':class_list_main[i]})):\n",
    "#                     print(class_list_main[i])\n",
    "                    content_list = soup.findAll(\"\",{'class':class_list_main[i]})\n",
    "#                     print (content_list)\n",
    "                    for content in content_list:\n",
    "                        scrape_details(content,news)\n",
    "                        break\n",
    "                else:\n",
    "                    content = soup\n",
    "                    scrape_details(content,news)\n",
    "    \n",
    "            print ('URL********************************************************')\n",
    "            print (news.articleUrl)\n",
    "            print ('TITLE********************************************************')\n",
    "            print (news.title)\n",
    "            print ('DATE********************************************************')\n",
    "            print (news.createdDate)\n",
    "            print ('AUTHOR********************************************************')\n",
    "            print (news.author)\n",
    "            print ('ARTICLE********************************************************')\n",
    "            print (news.article) \n",
    "        else:\n",
    "            print ('can not get the information!')\n",
    "    else:\n",
    "        print ('can not connect to the web page!')\n",
    "              \n",
    "\n",
    "def scrape_details(content, news):  \n",
    "#     print (content)\n",
    "#     print (content.find('',{'class':'b-item__title'}))\n",
    "    news.content = content\n",
    "    class_list_title = [\n",
    "                'ArticleHeader_headline_2zdFM',\n",
    "                'articleheader',\n",
    "                'entry-title',\n",
    "                'entry-title single-title',\n",
    "                'col-lg-9 col-md-8',\n",
    "                'content__headline',\n",
    "                'name post-title entry-title',\n",
    "                'articleTitle',\n",
    "                'artTitle',\n",
    "                'blog-title',\n",
    "                'b-item__title',\n",
    "                'postarea',\n",
    "                'full-page-article left-col',\n",
    "                'headline',\n",
    "                'post_title',\n",
    "                'post-title',\n",
    "                'post-headline',\n",
    "                'pg-headline',\n",
    "                'content-header ',\n",
    "                'field-subhead',\n",
    "                '_8UFs4BVE',\n",
    "                'headline',\n",
    "                'title',\n",
    "                'single-title',\n",
    "                'story-title',\n",
    "                'xxlarge'\n",
    "            ] \n",
    "    for i in range(len(class_list_title)):\n",
    "        if (content.find('',{'class':class_list_title[i]})):\n",
    "#             print (class_list_title[i])\n",
    "            news.title = content.find('',{'class':class_list_title[i]}).text         \n",
    "            break\n",
    "        else:\n",
    "            news.title = None\n",
    "#     if news.title is None:\n",
    "#         if (urlparse(news.articleurl).netloc) == 'www.abc.net.au':\n",
    "#             try:\n",
    "#                 news.title = content.find('h1').text\n",
    "#             except:\n",
    "#                 news.title = None\n",
    "#         else:\n",
    "#             news.title = None\n",
    "\n",
    "    class_list_paragraph = [\n",
    "                'ArticleBody__articleBody___1GSGP',\n",
    "                'art-postcontent',\n",
    "                'articles2',\n",
    "                'article-inner',\n",
    "                'article-text',                    \n",
    "                'article-content',\n",
    "                'article-copy',\n",
    "                'article_body',\n",
    "                'articleContentData',\n",
    "                'ArticleBody_body_2ECha',\n",
    "                'b-item__description',\n",
    "                'content-main',\n",
    "                'content-text', \n",
    "                'content__article-body from-content-api js-article__body',\n",
    "                'content',\n",
    "                'entry-content clearfix',\n",
    "                'entry-content full-content',\n",
    "                'entry clearfix',        \n",
    "                'entry-content', \n",
    "                'entry_content',\n",
    "                'entry-content print-only',\n",
    "                'entry-body',\n",
    "                'entry',                                       \n",
    "                'entry entry-content',\n",
    "                'event-text', \n",
    "                'entry-content-text',\n",
    "                'field-item even',\n",
    "                'field-items',\n",
    "                'field-body',\n",
    "                'infopage-news',\n",
    "                'td-post-content', \n",
    "                'the-content cf',\n",
    "                'thecontent',\n",
    "                'text-wrapper',\n",
    "                'td-post-content td-pb-padding-side',\n",
    "                'ntText',                          \n",
    "                'post-single',                     \n",
    "                'post-content entry-content cf',   \n",
    "                'post-body entry-content',        \n",
    "                'post_entry',                      \n",
    "                'post-content clearfix', \n",
    "                'post-bodycopy clearfix',\n",
    "                'post-single-content box mark-links',\n",
    "                'post-content',\n",
    "                'post-9141 post type-post status-publish format-standard has-post-thumbnail hentry category-world tag-fake-news tag-featured tag-satire',\n",
    "                'vw-post-content clearfix',\n",
    "                'wpb_wrapper',\n",
    "                'single-box clearfix entry-content',\n",
    "                'story-body story-body-1',\n",
    "                'sqs-block-content',\n",
    "                'single single-post postid-193191 single-format-standard',\n",
    "                'left relative',\n",
    "                'metadata__byline__author',\n",
    "                'mainContent',\n",
    "                'row'\n",
    "        \n",
    "    ]\n",
    "\n",
    "    news.article = []\n",
    "    for i in range(len(class_list_paragraph)):\n",
    "        if (content.find('',{'class': class_list_paragraph[i]})): \n",
    "#             print (class_list_paragraph[i])\n",
    "            paragraphs = content.find('',{'class': class_list_paragraph[i]})\n",
    "            if (paragraphs.findAll('p')):\n",
    "                for paragraph in paragraphs.findAll('p'):\n",
    "                    news.article.append(paragraph.text)\n",
    "                break\n",
    "        else:    \n",
    "            news.article = []\n",
    "\n",
    "    class_list_author = [\n",
    "                'postmetadata',\n",
    "                'author-article-link',\n",
    "                'ArticleHeader_byline_1VRIx'\n",
    "                'field-author',\n",
    "                'fn',\n",
    "                'name',\n",
    "                'url fn n',\n",
    "                'author vcard',\n",
    "                'author left-edge',\n",
    "                'author has-bio',\n",
    "                'author',\n",
    "                'artAuthor',\n",
    "                'post-author',\n",
    "                'meta pf-author',\n",
    "                'meta-author',\n",
    "                'author-name vcard fn',\n",
    "                'text font-accent color-brand size-1x-small _1HynphR0',\n",
    "                'byline-author',\n",
    "                'byline',\n",
    "                'createdby',\n",
    "                'username',\n",
    "                'single-author'\n",
    "    ]\n",
    "\n",
    "    for i in range(len(class_list_author)):\n",
    "        if (content.find('',{'class': class_list_author[i]})):\n",
    "#             print (class_list_author[i])\n",
    "            news.author = content.find(\"\",{'class':class_list_author[i]}).text \n",
    "            break\n",
    "        else:\n",
    "            news.author = None\n",
    "\n",
    "\n",
    "    class_list_date = [\n",
    "                'entry-date published',\n",
    "                'entry-date published updated',\n",
    "                'content-published-mobile',\n",
    "                'entry-date',\n",
    "                'entry-meta',\n",
    "                'entry-meta-date updated',\n",
    "                'byline byline-left ',\n",
    "                'bydate',\n",
    "                'b-item__asked-by-time',\n",
    "                'pub_date',\n",
    "                'post-date',\n",
    "                'post-date updated',\n",
    "                'published',\n",
    "                'timestamp',\n",
    "                'time',\n",
    "                'article-details',\n",
    "                'article_date',\n",
    "                'ArticleHeader_date_V9eGk',\n",
    "                'artData',\n",
    "                'field-post-date',\n",
    "                'fa fa-clock-o',\n",
    "                'update-time',\n",
    "                'row text font-accent size-1x-small color-darker-gray',\n",
    "                'dateline',\n",
    "                'date',\n",
    "                'content__dateline-lm js-lm u-h',\n",
    "                'grDate',\n",
    "                'submitted',\n",
    "                'single-date'\n",
    "    ]\n",
    "\n",
    "    for i in range(len(class_list_date)):\n",
    "        if (content.find('',{'class': class_list_date[i]})):\n",
    "#         print(class_list_date[i])\n",
    "            news.createdDate = content.find('',{'class': class_list_date[i]})\n",
    "#             print (news.createdDate.text)\n",
    "            try:\n",
    "                news.createdDate = (parser.parse(news.createdDate['datetime'])).isoformat()\n",
    "            except:\n",
    "                try:\n",
    "                    news.createdDate = (parser.parse(news.createdDate.text)).isoformat()\n",
    "                except:\n",
    "                    news.createdDate = None\n",
    "            break\n",
    "        else:\n",
    "            news.createdDate = None\n",
    "\n",
    "    return\n",
    "# RELIABLE:\n",
    "# bbc\n",
    "# link = 'http://www.abc.net.au/news/2017-07-24/top-water-bureaucrat-offered-confidential-documents-to-lobbyists/8738568'\n",
    "# link = 'https://www.theguardian.com/us-news/2017/jul/21/sean-spicer-resigns-press-secretary-trump-white-house-feud'\n",
    "# link = 'http://www.reuters.com/article/us-usa-trump-russia-lawyer-exclusive-idUSKBN1A61LZ'\n",
    "# link = 'http://www.thedailysheeple.com/ex-nasa-scientist-claims-ufos-are-hiding-in-saturns-rings_072017'\n",
    "# link = 'https://www.nytimes.com/2017/07/20/arts/music/chester-bennington-linkin-park-dead.html'\n",
    "# link = 'http://time.com/4867932/donald-trump-investigate-robert-mueller-aides/'\n",
    "# ilnk = 'http://edition.cnn.com/2017/07/21/politics/sean-spicer-resigns-anthony-scaramucci/index.html'\n",
    "# link = 'http://www.independent.co.uk/news/world/americas/russian-lawyer-donald-trump-jr-natalia-veselnitskaya-fsb-client-moscow-intelligence-agency-kremlin-a7853251.html'\n",
    "# FAKE:\n",
    "# link = 'http://www.thedailysheeple.com/astronomers-detect-strange-radio-signals-from-nearby-star_072017'\n",
    "# link = 'http://awm.com/will-this-latest-blunder-be-the-final-nail-in-the-coffin-for-the-worst-show-in-tv-history/?utm_medium=homepage&utm_source=homepage1'\n",
    "# link = 'http://americannews.com/beware-new-doll-meant-indoctrinate-sharia-law-children-coming-home/'\n",
    "# link = 'http://alternativemediasyndicate.com/2017/07/12/citizens-right-defend-police-brutality/'\n",
    "# link = 'http://www.bostonleader.com/us-regulator-warns-consumers-of-fire-hazard-from-samsung-phones/'\n",
    "# UNRELIABLE:\n",
    "# link = 'http://www.anonews.co/cop-drugs-frame/'\n",
    "link = 'http://anonhq.com/london-terror-attacks-brits-celebrating-beer-hero/'\n",
    "# link = 'http://www.asia-pacificresearch.com/indias-caste-system-social-inequality-and-demonetization/5568095'\n",
    "# link = 'https://www.newsbud.com/2017/07/20/european-bank-failures-a-bellwether-for-another-imminent-2008-financial-crisis/'\n",
    "# SATIRE\n",
    "# link = 'http://empirenews.net/hillary-clinton-undergoes-sex-change-operation-so-she-has-a-better-chance-at-winning-2020-election/'\n",
    "# link = 'http://realnewsrightnow.com/2017/05/texas-lawmaker-called-ice-mother-law-dinner-table-dispute/'\n",
    "# link = 'http://usadailytime.com/belligerent-professor-suspended-indefinitely-heated-round-tucker/'\n",
    "# link = 'http://beehivebugle.com/2017/05/23/monson-eschews-prophetic-duties-cheer-apostate-facebook-drama/'\n",
    "# Conspiracy:\n",
    "# link = 'http://anotherdayintheempire.com/distraction-du-jour-trump-punches-cnn/'\n",
    "# link = 'http://conservativefiringline.com/va-removes-top-2-officials-manchester-va-hospital/'\n",
    "# link = 'http://www.brotherjohnf.com/death-equity-research-hasnt-greatly-exaggerated/'\n",
    "# link = 'http://conservativetribune.com/msnbc-hosts-attack/'\n",
    "# HATE:\n",
    "# link = 'http://www.frontpagemag.com/fpm/267321/nevertrump-nostalgia-hillary-never-was-daniel-greenfield'\n",
    "# link = 'http://www.vdare.com/articles/said-in-spanish-dual-citizen-actress-activist-tells-illegals-how-not-to-get-arrested-a-new-app-for-dreamers-the-america-thing-etc'\n",
    "# link = 'http://www.infostormer.com/fbi-apparently-seized-smashed-computer-hard-drives-from-home-of-jewess-debbie-wasserman-schultz/'\n",
    "# link = 'http://www.actforamerica.org/12000shariahfine'\n",
    "# BIAS\n",
    "# link = 'http://www.americanthinker.com/articles/2017/07/europe_downward_now_the_bavarians_want_to_leave.html'\n",
    "# link = 'http://100percentfedup.com/watch-rep-steve-kings-bombshell-answer-trumps-wall-hasnt-built-yet-video/'\n",
    "# link = 'https://www.ammoland.com/2017/07/cheetah-12-shotgun-review/#axzz4npPZrytk'\n",
    "# link = 'http://www.charismanews.com/opinion/66433-exactly-how-many-items-have-been-checked-off-on-jesus-end-times-list'\n",
    "# Junk:\n",
    "# link = 'http://www.celebtricity.com/nicki-minaj-files-10m-lawsuit-against-remy-ma-for-using-her-voice-in-diss-song-on-itunes/'\n",
    "# link = 'https://www.scoopwhoop.com/india-inhuman-rape-cases/#.6j9dfreps'\n",
    "# link = 'http://yournewswire.com/fbi-hard-drives-wasserman-schultz/'\n",
    "# link = 'http://awarenessact.com/fukushima-plant-set-to-release-770000-tons-of-highly-radioactive-water-material-into-ocean/'\n",
    "\n",
    "# Political:\n",
    "# link = 'http://thelastlineofdefense.org/breaking-president-trump-wants-you-to-know-the-truth-about-agenda-21/'\n",
    "# link = 'http://www.defenddemocracy.press/one-week-after-mosuls-liberation-horror-of-us-siege-continues-to-unfold/'\n",
    "# link = 'https://www.advocate.com/politics/2017/7/24/donald-trump-blocks-rosie-odonnell-twitter'\n",
    "# link = 'http://www.breitbart.com/big-government/2017/07/24/study-8471-cases-double-voting-uncovered-21-states/'\n",
    "# CLICKBAIT\n",
    "# link = 'http://americablog.com/2017/07/cbo-gop-obamacare-repeal-22m-uninsured-13k-deductible-premiums-soar-older.html'\n",
    "# link = 'http://americanlookout.com/rms-corruption-more-obama-officials-scrutinized-in-unmasking-probe-video/'\n",
    "# link = 'https://www.americasfreedomfighters.com/2017/07/24/top-marine-general/'\n",
    "# link = 'https://ihavethetruth.com/2017/07/24/postal-service-helped-hillary/'     # aritcle = [] or over 1000\n",
    "scraping(link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py3k",
   "language": "python",
   "name": "py3k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
